{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f47a5ab19bc45083382657f6f2388be666e731531973f00c5e26ff8c66213130"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py\u001b[0m in \u001b[0;36mfind_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ERR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# use `dlopen()` for dynamic loading.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-692af2fa52bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mexit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0msource\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrelaunch\u001b[0m \u001b[0myour\u001b[0m \u001b[0mpython\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m from there.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 60\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"C:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there."
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformations  as tr\n",
    "import random as rand\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePairs(frames):\n",
    "    framePairs = [] #vector to hold image pairs\n",
    "\n",
    "    for x in range(len(frames)): #x represents the first frame in the pair\n",
    "        for y in range(len(frames)-3-x): #y represents second frame in the pair\n",
    "            pair = [(x+1),(x+y+4),np.stack((frames[x], frames[x+y+3]), axis=-1)] #generate pair\n",
    "            framePairs.append(pair)\n",
    "    return framePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translatePair(pair,steps,patient):\n",
    "\n",
    "    frame1 = pair[0]-1 #get first frame position from pair object\n",
    "    frame2 = pair[1]-1 #get second frame position from pair object\n",
    "    JAdd = pair[2].shape[0] #Get size of original frame to keep translation size consistent\n",
    "    IAdd = pair[2].shape[1] #Get size of original frame to keep translation size consistent\n",
    "\n",
    "    baseCut = 0.1 #use same base cut as is used in original frame generation\n",
    "    step = baseCut/steps #set step size to be as large as possible for given number of steps\n",
    "    pairs = [] #vector to hold newly generated pairs\n",
    "\n",
    "    #adjust how the frame is cropped from the original data to simulate translation\n",
    "    for x in range(-steps,steps+1): \n",
    "        for y in range(-steps,steps+1):\n",
    "            lowerI = int((cutLeft+x*step)*256)\n",
    "            upperI = lowerI+IAdd\n",
    "            lowerJ = int((cutTop+y*step)*2592)\n",
    "            upperJ = lowerJ+JAdd\n",
    "\n",
    "            first = rawData[patient][1][lowerJ:upperJ,lowerI:upperI,frame1]\n",
    "            second = rawData[patient][1][lowerJ:upperJ,lowerI:upperI,frame2]\n",
    "\n",
    "            pairs.append(np.stack((first,second), axis=-1)) #append translated pair to pairs vector\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(min,max,array):\n",
    "    test[test < min] = min\n",
    "    test[test > max] = max\n",
    "    array = tr.unit_vector(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory containing the RF scan data\n",
    "dataFolder = 'C:/Users/Lucas/OneDrive - The University of Western Ontario/Documents/GitHub/SE4450-project-code/Preprocessing/'\n",
    "\n",
    "#Vector to hold all training data sets\n",
    "rawData = []\n",
    "\n",
    "#Loading in the matlab file information\n",
    "rawMatFile = loadmat(dataFolder+'P39-W2-S4')\n",
    "#Contains just the RF data pulled from the .mat file\n",
    "P39W2S4 = rawMatFile['rf1']\n",
    "rawData.append(['P39W2S4',P39W2S4])\n",
    "\n",
    "#repeat above steps for other RF files\n",
    "rawMatFile = loadmat(dataFolder+'P39-W4-S6')\n",
    "P39W4S6 = rawMatFile['rf1']\n",
    "rawData.append(['P39W4S6',P39W4S6])\n",
    "rawMatFile = loadmat(dataFolder+'P82-W0-S2')\n",
    "P82W0S2 = rawMatFile['rf1']\n",
    "rawData.append(['P82W0S2',P82W0S2])\n",
    "rawMatFile = loadmat(dataFolder+'P87-W0-S3')\n",
    "P87W0S3 = rawMatFile['rf1']\n",
    "rawData.append(['P87W0S3',P87W0S3])\n",
    "rawMatFile = loadmat(dataFolder+'P87-W2-S4')\n",
    "P87W2S4 = rawMatFile['rf1']\n",
    "rawData.append(['P87W2S4',P87W2S4])\n",
    "rawMatFile = loadmat(dataFolder+'P90-W0-S4')\n",
    "P90W0S4 = rawMatFile['rf1']\n",
    "rawData.append(['P90W0S4',P90W0S4])\n",
    "rawMatFile = loadmat(dataFolder+'P94-W1-S3')\n",
    "P94W1S3 = rawMatFile['rf1']\n",
    "rawData.append(['P94W1S3',P94W1S3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1805, 205, 2)\n"
     ]
    }
   ],
   "source": [
    "#leave a slice of each edge of the scan from being black\n",
    "cutTop = 0.1\n",
    "cutLeft = 0.1\n",
    "cutBottom = 0.1\n",
    "cutRight = 0.1\n",
    "\n",
    "lowerI = int(cutLeft*256)\n",
    "upperI = int((1-cutRight)*256)\n",
    "lowerJ = int(cutTop*2592)\n",
    "upperJ = int((1-cutBottom)*2592)\n",
    "\n",
    "allFrames = [] #vector to hold individual cropped frames\n",
    "\n",
    "for y in range(len(rawData)):\n",
    "    frames = []\n",
    "    for x in range(rawData[y][1].shape[2]): #range is how many frames there are in the set\n",
    "        frames.append(rawData[y][1][lowerJ:upperJ,lowerI:upperI,x]) #Take inner subset of frame to allow for translation\n",
    "    allFrames.append([rawData[y][0],frames])\n",
    "\n",
    "pairs = []\n",
    "for x in range(len(allFrames)):\n",
    "    pairs.append([allFrames[x][0],generatePairs(allFrames[x][1])]) #add generated pairs to list\n",
    "print(pairs[6][1][0][2].shape)\n",
    "\n",
    "#PAIRS VARIABLE GUIDE\n",
    "#First value = Holds which patient set is being referred to\n",
    "#Second value = Holds either patient set name [0] or generated pairs for set\n",
    "#Third value = Holds all pairs for patient set\n",
    "#Fourth value = holds specific pairs for patient set\n",
    "#pairs[0][1][0][2].shape <- references the shape of the third pair of frames for a certain patients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1134\n"
     ]
    }
   ],
   "source": [
    "#Create Vector of stacked pairs with frame number and patient ID for easy labeling\n",
    "data = []\n",
    "for x in range(len(pairs)):\n",
    "    for y in range(len(pairs[x][1])):\n",
    "        data.append([pairs[x][0],pairs[x][1][y][0],pairs[x][1][y][1],pairs[x][1][y][2]])\n",
    "\n",
    "print(len(data))\n",
    "#for x in range(200):\n",
    "#    print(data[x][0],data[x][1],data[x][2],data[x][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in label data\n",
    "DFP39W2S4 = pd.read_excel('Labels.xlsx', sheet_name='P39-W2-S4', engine='openpyxl')\n",
    "DFP39W4S6 = pd.read_excel('Labels.xlsx', sheet_name='P39-W4-S6', engine='openpyxl')\n",
    "DFP82W0S2 = pd.read_excel('Labels.xlsx', sheet_name='P82-W0-S2', engine='openpyxl')\n",
    "DFP87W0S3 = pd.read_excel('Labels.xlsx', sheet_name='P87-W0-S3', engine='openpyxl')\n",
    "DFP87W2S4 = pd.read_excel('Labels.xlsx', sheet_name='P87-W2-S4', engine='openpyxl')\n",
    "DFP90W0S4 = pd.read_excel('Labels.xlsx', sheet_name='P90-W0-S4', engine='openpyxl')\n",
    "DFP94W1S3 = pd.read_excel('Labels.xlsx', sheet_name='P94-W1-S3', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1134\n"
     ]
    }
   ],
   "source": [
    "#create labels for training data\n",
    "labels = DFP39W2S4['Label axial'].tolist() + DFP39W4S6['Label axial'].tolist() + DFP82W0S2['Label axial'].tolist() + DFP87W0S3['Label axial'].tolist() + DFP87W2S4['Label axial'].tolist() + DFP90W0S4['Label axial'].tolist() + DFP94W1S3['Label axial'].tolist()\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledData = []\n",
    "for x in range(len(labels)):\n",
    "    labeledData.append([data[x][3],labels[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "240\n894\n240\n240\n<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "goodData = []\n",
    "badData = []\n",
    "for x in range(len(labeledData)):\n",
    "    if labeledData[x][1] > 0:\n",
    "        goodData.append(labeledData[x])\n",
    "    else:\n",
    "        badData.append(labeledData[x])\n",
    "print(len(goodData))\n",
    "print(len(badData))\n",
    "badData = rand.sample(badData,len(goodData))\n",
    "print(len(goodData))\n",
    "print(len(badData))\n",
    "balancedData = goodData+badData\n",
    "print(type(balancedData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in the ratio 80-20 for training and validation.\n",
    "X_train, X_test, y_train, y_test = train_test_split([x[0] for x in balancedData], [x[1] for x in balancedData], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}